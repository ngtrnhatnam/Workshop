[
{
	"uri": "//localhost:1313/5-lambda-api-setup/5.1-create-lambda-save-history/",
	"title": "Create Lambda Function for History Saving",
	"tags": [],
	"description": "",
	"content": " Goal: Create a Lambda function using Python to save prediction history into DynamoDB.\n1. Create a New Lambda Function Go to AWS Console → Lambda\nFigure 1: Searching and accessing Lambda service in AWS Console.\nClick on the Functions tab → hit Create function.\nFigure 2: Starting to create the SavePredictionHistory function.\nChoose Author from scratch.\nFunction name: SavePredictionHistory.\nRuntime: Python 3.13 or the latest available version.\nClick Create function.\nFigure 3: Setting up Lambda function details.\n2. Configure the Lambda Function Code After creation, the console will navigate you to the function configuration screen\nFigure 4: Lambda function configuration screen.\n-Open your project folder and locate the code at src/lambda/lambda_history.py. Copy all the code inside.\n![Copy function](/images/5.lambda-api-setup/5.1.create-lambda-save-history/create-lambda-save-history-5.png) *Figure 5: Copying the Lambda function code.* Return to the AWS Console under the Code tab (which looks like VS Code)\nPaste the copied code, then click Deploy\nFigure 6: Deploying the Lambda function.\n3. Set Up IAM Role for Lambda Go to AWS Console → IAM\nFigure 7: Searching and accessing IAM service.\nClick on Access managemen → Roles, then search for SavePredictionHistory role. It will look like SavePredictionHistory-role-xxxxx. Click it.\nFigure 8: Searching for the IAM Role.\nIn the Permissions policies, click Add permissions on the right side, then choose Attach Policies.\nFigure 9: Adding permissions for Lambda.\nSearch for AmazonDynamoDBFullAccess, check the box, and click Add permissions\nFigure 10: Adding DynamoDB access permission to Lambda.\nPretty easy, right?\nIf you’ve completed this step and feel ready, let’s move on to Setting up the Lambda function to call the SageMaker Endpoint!\n"
},
{
	"uri": "//localhost:1313/3-quick-create-sagemaker-ai/3.1-set-up-sagemaker-ai/",
	"title": "Set up SageMaker AI",
	"tags": [],
	"description": "",
	"content": " Objective: Launch SageMaker AI using Quick setup for a single user, ready to deploy AI models.\n1. Access SageMaker Log in to AWS Management Console. Search for SageMaker and open the service. Figure 1: Searching and accessing SageMaker service in AWS Console.\n2. Choose Quick setup On the SageMaker main screen, find the section New to SageMaker AI? Click Set up for single user. Figure 2: Quick setup option for a single user.\n3. Confirm default configuration AWS will automatically propose a configuration and default settings, you just need to wait. Figure 3: Quick setup configuration confirmation.\n4. Wait for initialization Initial status: Pending → will change to InService once ready. This usually takes a few minutes. Done?\nNext, we’ll Upload trained model.\n"
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Explore the power of real-time AI in the cloud!\nThis workshop will guide you step-by-step to build a serverless image recognition web application, using AWS services to process, predict, and store image-based data in a fast, secure, and cost-effective way.\nIn the era of AI, building real-time applications that are scalable, secure, and easy to maintain is a top priority. The workshop \u0026ldquo;Deploying a Serverless Real-Time Image Recognition Application with Lambda and Sagemaker\u0026rdquo; will help you integrate a pre-trained Machine Learning model into a web interface, enabling real-time predictions without managing servers.\nThe application supports:\nUploading an image directly from your browser. Instant predictions from a deployed ML model. Saving prediction history to DynamoDB for tracking. Simple and responsive UI for smooth interaction. Serverless architecture — no need for server maintenance. Benefits of Serverless Applications The AWS serverless stack brings multiple benefits for AI-powered applications:\n1. Real-Time Processing AWS Lambda executes predictions immediately upon receiving an image, ensuring low-latency responses.\nExample: A user uploads an image of a handwritten digit, and the system instantly returns the predicted digit.\n2. Automatic Scaling Lambda scales automatically based on demand — whether 1 or 1,000 users upload images simultaneously.\n3. Secure Data Handling API Gateway works with IAM roles and resource policies to ensure:\nOnly authorized calls reach the Lambda functions. DynamoDB write/read access is strictly role-based. Example: The prediction Lambda can only write to the PredictionHistory table, not delete data.\n4. Cost Efficiency You only pay for what you use:\nLambda: Charged per execution time. DynamoDB: Pay-per-request pricing. S3: Pay for stored static assets. 5. Fast Access \u0026amp; Smooth Experience The web interface (HTML, CSS, JS) will run locally using VS Code’s Live Server. This approach allows you to develop, test, and modify the UI quickly without deploying static files to S3.\nWorkshop Goals By completing this workshop, you will learn how to:\nGoal Technology Outcome Design a simple, responsive UI HTML, CSS Easy-to-use image upload interface Build and secure APIs API Gateway Endpoints for image submission \u0026amp; prediction Deploy ML inference AWS Lambda, SageMaker Endpoint Real-time predictions from a pre-trained model Store results DynamoDB Persistent prediction history Distribute globally S3, CloudFront Fast, worldwide content delivery Monitor and debug CloudWatch Insight into system performance Start Your Journey! By the end of this workshop, you will have:\nA working real-time image recognition app. Hands-on experience connecting AWS services into a serverless workflow. Skills to deploy AI-powered apps without managing servers. Ready to start?\nMove on to Preparation Steps to set up your AWS environment!\n"
},
{
	"uri": "//localhost:1313/5-lambda-api-setup/5.2-create-lambda-call-sagemaker/",
	"title": "Create Lambda Function call SageMaker Endpoint",
	"tags": [],
	"description": "",
	"content": " Goal: Create a Lambda function using Python to save prediction history into DynamoDB.\n1. Create a New Lambda Function Go to AWS Console → Lambda\nFigure 1: Searching and accessing Lambda service in AWS Console.\nClick on the Functions tab → hit Create function.\nFigure 2: Starting to create the SavePredictionHistory function.\nChoose Author from scratch.\nFunction name: SavePredictionHistory.\nRuntime: Python 3.13 or the latest available version.\nClick Create function.\nFigure 3: Setting up Lambda function details.\n2. Configure the Lambda Function Code After creation, the console will navigate you to the function configuration screen\nFigure 4: Lambda function configuration screen.\n-Open your project folder and locate the code at src/lambda/lambda_history.py. Copy all the code inside.\n![Copy function](/images/5.lambda-api-setup/5.1.create-lambda-save-history/create-lambda-save-history-5.png) *Figure 5: Copying the Lambda function code.* Return to the AWS Console under the Code tab (which looks like VS Code)\nPaste the copied code, then click Deploy\nFigure 6: Deploying the Lambda function.\n3. Set Up IAM Role for Lambda Go to AWS Console → IAM\nFigure 7: Searching and accessing IAM service.\nClick on Access managemen → Roles, then search for SavePredictionHistory role. It will look like SavePredictionHistory-role-xxxxx. Click it.\nFigure 8: Searching for the IAM Role.\nIn the Permissions policies, click Add permissions on the right side, then choose Attach Policies.\nFigure 9: Adding permissions for Lambda.\nSearch for AmazonDynamoDBFullAccess, check the box, and click Add permissions\nFigure 10: Adding DynamoDB access permission to Lambda.\nContinue by selecting Add permissions on the right-hand side, then choose Create Inline Policy.\nNext, in the Policy Editor, switch to the JSON.\nFigure 11: Adding additional permissions to Lambda.\nPaste the following code into the editor, then click Next:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sagemaker:InvokeEndpoint\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Figure 12: Adding InvokeEndpoint permission for Lambda.\nIn the Policy name field, enter Invoke-endpoint, and finally click Create Policy Figure 13: Completing permission setup for Lambda.\nPretty easy, right?\nIf you’ve completed this step and feel ready, let’s move on to Create API Gateway!\n"
},
{
	"uri": "//localhost:1313/3-quick-create-sagemaker-ai/3.2-upload-trained-model/",
	"title": "Upload a Trained Model",
	"tags": [],
	"description": "",
	"content": " Objective: Guide on updating IAM Role and uploading a pre-trained model to SageMaker using Python script.\n1. Prepare the model In the project folder under assets/models, you are provided with two files:\ninference.py (inference script) mobilenetv3_small.pt (pre-trained model file) Figure 1: The two provided files.\nPackage these two files into a model.tar.gz archive so SageMaker can use them, then go back to the root directory for convenience:\ncd assets/models tar -czvf model.tar.gz mobilenetv3_small.pt inference.py cd ../.. Figure 2: After packing the files and returning to the root folder.\n2. Get the ARN of the auto-created IAM Role Go to AWS Console → IAM → Roles.\nFigure 3: Search and access SageMaker service in AWS Console.\nFind the auto-created SageMaker Role with name like: AmazonSageMaker-ExecutionPolicy-xxxxxxx.\nFigure 4: Search and find the SageMaker Role.\nCopy the ARN of this Role..\nFigure 5: Copy the ARN of the SageMaker Role.\n3. Update IAM Role trong script deploy Update IAM Role in deploy script src/sagemaker/deploy_model.py in project.\nPress Ctrl + F, and search for role = \u0026quot;\u0026quot;.\nFigure 6: Find where to update the ARN.\nReplace the role value inside the quotes with the ARN you copied..\nFigure 7: Replace with the ARN copied earlier.\n4. Run the deploy script Open your terminal and run:\npython src/sagemaker/deploy_model.py The script will upload model.tar.gz to S3 and deploy the SageMaker Endpoint.\n5. Update the endpoint in the deploy script Open the file located at src/lambda/lambda_function.py in project.\nPress Ctrl + F, and search for EndpointName=.\nFigure 9: Search for the location where the Endpoint needs to be updated.\nReplace the value inside the single quotes ' ' with the Endpoint you copied earlier.\nFigure 10: Replace the Endpoint copied in the step shown in Figure 8.\nFinally, press Ctrl + S to save the file.\nAll done?\nNow you can move on to Create DynamoDB Table!\n"
},
{
	"uri": "//localhost:1313/2-preparation-steps/2.1-install-necessary-tool/",
	"title": "Install Necessary Tools",
	"tags": [],
	"description": "",
	"content": " Goal: Install Python, VS Code, AWS CLI, and required Python libraries to develop our cute little serverless image recognition app. 🐣\nPrerequisites Before we dive in, let’s make sure your computer is ready to roll with all the essential tools! 🚀\n1. Python Download and install Python. Check the installation with: python --version If you see something like this, we’re good to go: Python 3.xx.x x means the version number. For example, mine is Python 3.13.1 — totally fine! 💖\nFigure 1: Console showing Python version check after installation.\n2. Visual Studio Code (VS Code) Download and install VS Code. Add these handy extensions: Python (Microsoft):\nFigure 2: Installing the Python extension in VS Code.\nLive Server (to run your web interface locally):\nFigure 3: Installing the Live Server extension in VS Code.\n3. AWS CLI Download and install AWS CLI. Check the installation with: aws --version If you get a result in the format below, then we can move on to the next step: aws-cli/2.27.52 Python/3.13.4 Windows/11 exe/AMD64 Numbers may vary depending on your OS, Python version, and chipset — no worries! 💪\nFigure 4: Console showing AWS CLI version check after installation.\nAll set?\nLet’s hop over to Set up the Environment and keep the fun going! ✨\n"
},
{
	"uri": "//localhost:1313/2-preparation-steps/",
	"title": "Preparation Steps",
	"tags": [],
	"description": "",
	"content": " Goal: Set up everything you need to deploy a serverless image recognition app, including your AWS account, IAM Roles, Lambda, API Gateway, DynamoDB table, and SageMaker.\nTo kick off the \u0026ldquo;Deploying a Real-Time Serverless Image Recognition App with Lambda and SageMaker\u0026rdquo; workshop, you’ll need to prepare the basic building blocks so they all work smoothly together with AWS services like Lambda, DynamoDB, API Gateway, and the SageMaker Endpoint.\nInitial Requirements You’ll need an AWS account to complete the steps in this workshop. If you don’t have one yet, create it before continuing.\n📖 Reference: How to create an AWS account\nPreparation Checklist Step Title Description 2.1 Install necessary tools Install Python, VS Code, AWS CLI, and the required Python libraries. 2.2 Set up your environment Configure your workspace and test AWS CLI connection. Note: Follow the steps in order to ensure your environment is set up correctly. Each step will be explained in detail in its own guide.\nConclusion Once you’ve completed these preparation steps, you’ll have:\nAn AWS Account ready to use. All development tools (Python, VS Code, AWS CLI, required libraries) installed. A workspace configured to connect with AWS. Everything in place to start building your serverless image recognition app. All set?\nLet’s move on to Install necessary tools and get started — hope you’re ready! 🚀\n"
},
{
	"uri": "//localhost:1313/2-preparation-steps/2.2-set-up-environment/",
	"title": "Set Up Environment",
	"tags": [],
	"description": "",
	"content": " Goal: Fork \u0026amp; clone the project, create a virtual environment, and install required Python libraries to run the application.\n1. Fork and Clone the Project Go to the GitHub repo: Serverless-ML-Inference-with-Lambda-and-SageMaker Click Fork to create a copy under your own GitHub account. Clone it to your machine: git clone https://github.com/\u0026lt;your-username\u0026gt;/Serverless-ML-Inference-with-Lambda-and-SageMaker cd Serverless-ML-Inference-with-Lambda-and-SageMaker code . 2. Create and Activate Virtual Environment Create Virtual Environment: python -m venv .venv And then activate it:\nWindows: .venv\\Scripts\\activate macOS / Linux: source .venv/bin/activate If successful, you’ll see the environment name (e.g., .venv) at the beginning of the terminal line.\nHình 1: Check the virtual environment if it activated.\n3. Install Required Libraries Quick install these required libraries: pip install boto3 sagemaker torch torchvision pillow Note:\nIf you plan to train models locally, ensure gcc or the corresponding build tools are installed for your OS. torch installation might take a few minutes depending on your internet speed. Seem easy right!?\nLet’s move to Quick set up Sagemaker AI to start interacting with AWS! 🚀\n"
},
{
	"uri": "//localhost:1313/5-lambda-api-setup/5.3-create-api-gateway/",
	"title": "Create API Gateway",
	"tags": [],
	"description": "",
	"content": " Target: Create an API Gateway to interact with Lambda.\n1. Create API Gateway Go to AWS Console → API Gateway.\nFigure 1: Searching and accessing API Gateway service in AWS Console.\nSelect the APIs tab → click Create API.\nFigure 2: Starting to create a new API.\nIn HTTP API, choose Build.\nFigure 3: Selecting HTTP API type.\nIn Step 1, set the API name as MLInferenceAPI, then click Next.\nFigure 4: Naming the API.\nIn Step 2, click Next; in Step 3, set the Stage name as prod, then continue with Next.\nFigure 5: Setting Stage name.\nIn Step 4, click Create.\nFigure 6: Finishing API setup.\n2. Set up API routes The screen will switch to the Develop → Routes tab. Here, set up routes to attach Lambda functions later. Click Create.\nFigure 7: Creating routes.\nCreate two routes:\n/history Figure 8: Creating /history route.\n/predict Figure 9: Creating /predict route.\nConclusion Now your API is ready to receive requests from the frontend!\nSeem easy, right?\nIf you’re done, move on to Web interface and continue your serverless journey! 🚀✨\n"
},
{
	"uri": "//localhost:1313/3-quick-create-sagemaker-ai/",
	"title": "Quick Create SageMaker AI",
	"tags": [],
	"description": "",
	"content": " Goal: Quickly set up an AI model on AWS SageMaker, ready to integrate into your serverless image recognition application.\nIntroduction In this section, we will quickly create SageMaker AI to support real-time image recognition.\nThe process includes:\nCreating a SageMaker Studio for development. Configuring an IAM Role so SageMaker can access S3, Lambda, and other related AWS services. Uploading a pre-trained model to get it ready for deployment. Main Steps Step Description 3.1 Set up SageMaker AI 3.2 Set up IAM Role for SageMaker 3.3 Upload Pre-trained Model Note: Make sure you have completed Section 2 – Preparation Steps before moving on, so your AWS environment and tools are ready.\nConclusion By completing this section, you will:\nHave a fully working SageMaker environment. Have given SageMaker the necessary permissions. Uploaded your model, ready for serverless deployment. Ready to roll?\nLet’s start with Set up SageMaker AI!\n"
},
{
	"uri": "//localhost:1313/4-create-dynamodb/",
	"title": "Create DynamoDB Table: PredictionHistory",
	"tags": [],
	"description": "",
	"content": " Objective: Understand DynamoDB and create the PredictionHistory table to store image prediction history.\nIntroduction to DynamoDB DynamoDB is AWS\u0026rsquo;s serverless NoSQL database service, super fast, auto-scalable, and serverless. Perfect for storing data like prediction history in a serverless app.\nCreate PredictionHistory table Go to AWS Console → DynamoDB\nFigure 1: Find DynamoDB services.\nContinue select Table → Create Table to create new table\nFigure 2: Click Create Table to start create new table.\nTable name: PredictionHistory.\nPartition key: id (Kiểu String).\nYou can skip Sort key (not needed).\nFigure 3: Set up attribute for table.\nKeep other settings default and click Create table.\nFigure 4: Click Create Table to finish create table.\nConclusion Now your PredictionHistory table is ready to store data from Lambda functions. Next, we\u0026rsquo;ll create Lambda functions to use this table!\nReady to go?\nMove on to Create Lambda function and API Gateway\n"
},
{
	"uri": "//localhost:1313/5-lambda-api-setup/",
	"title": "Introduction to Lambda and API Gateway",
	"tags": [],
	"description": "",
	"content": " Objective: Understand the role of AWS Lambda and API Gateway in the serverless image recognition application.\nWhat is AWS Lambda? AWS Lambda is AWS’s serverless compute service that lets you run code without managing servers. Lambda automatically scales and charges you only for the compute time you consume.\nLambda’s role in this workshop:\nHandle user requests (image upload, prediction calls). Store prediction history into DynamoDB. Call the Machine Learning model on SageMaker to return prediction results. What is API Gateway? API Gateway is AWS’s API management service that helps you create, secure, monitor, and operate RESTful or WebSocket APIs.\nIts role in the workshop:\nProvide a RESTful endpoint for the frontend to send images and receive prediction results. Connect to Lambda functions that handle backend logic. Manage security and access permissions for the API. Overall Architecture Frontend → API Gateway → Lambda (gọi SageMaker) → SageMaker Endpoint → Lambda (lưu lịch sử) → DynamoDB\nMain Steps Step Description 5.1 Create Lambda Function to save history 5.2 Create Lambda Function to call SageMaker endpoint 5.3 Create API Gateways Ready?\nNext, we’ll create the Lambda function to save history in Create Lambda Function to save history!\n"
},
{
	"uri": "//localhost:1313/6-web-interface/",
	"title": "Designing the Web Interface",
	"tags": [],
	"description": "",
	"content": " Objective: Build a simple, user-friendly web interface that allows users to upload images for prediction.\n1. Overview The web interface is designed to be simple and easy to use, focusing on the main features: uploading an image and displaying prediction results clearly.\nSupports uploading images directly from the user’s device. Displays the uploaded image along with the prediction result below it. Includes a “Predict” button to call the backend API. Responsive design for both desktop and mobile devices. 2. Technologies Used HTML5 for page structure. CSS3 for clean and user-friendly styling. Vanilla JavaScript to handle interactions such as image upload, API calls, and result display. 3. Main Page Structure \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Cat vs Dog Classifier\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;style.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Cat or Dog?\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;Upload an image to classify\u0026lt;/h2\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; id=\u0026#34;imageInput\u0026#34; accept=\u0026#34;image/*\u0026#34; /\u0026gt; \u0026lt;div id=\u0026#34;previewBox\u0026#34; style=\u0026#34;display:none;\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;Your selected image:\u0026lt;/h3\u0026gt; \u0026lt;img id=\u0026#34;previewImage\u0026#34; src=\u0026#34;\u0026#34; alt=\u0026#34;Preview\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button onclick=\u0026#34;sendImage()\u0026#34;\u0026gt;Predict\u0026lt;/button\u0026gt; \u0026lt;p id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;div id=\u0026#34;history\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Recent Prediction History\u0026lt;/h2\u0026gt; \u0026lt;ul id=\u0026#34;historyList\u0026#34;\u0026gt;\u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4. Notes The “Predict” button will call the backend API via JavaScript fetch. The selected image is previewed immediately so the user can confirm it’s correct. Prediction results are displayed inside the #result element. Simple and clean design for easy maintenance and future upgrades. 5. Updating API Endpoints in JavaScript Go to AWS Console → API Gateway\nFigure 1: Search for API Gateway in the console.\nNavigate to the Function tab → select the InvokeModelLambda function\nFigure 2: Accessing InvokeModelLambda.\nOpen the Configuration tab → Trigger. Under API Endpoint, copy the full URL. The format is: https://xxxx.execute-api.\u0026lt;your-region\u0026gt;.amazonaws.com/prod/predict.\nFigure 3: Copying the API endpoint.\nGo back to your project, open the script.js file. Press Ctrl + F, search for Change predict. and replace the URL inside the quotes \u0026quot; \u0026ldquo; with the copied API endpoint.\nFigure 4: Replacing the API endpoint.\nRepeat the same process for SavePredictionHistory: But in project, search for Change history in script.js and replace the URL inside the quotes \u0026quot; \u0026ldquo;.\n-Save the file Ctrl + S.\nReady?\nNext, let’s move on to Check the Results to verify the entire system is working properly!\n"
},
{
	"uri": "//localhost:1313/7-check-result/",
	"title": "Check the Result",
	"tags": [],
	"description": "",
	"content": " Goal: Verify that the entire system (Web UI → API Gateway → Lambda → SageMaker → DynamoDB) works smoothly.\n1. Open the Web Interface Go back to your project in VS Code.\nLocate the main.html file.\nRight-click on it and choose Open with Live Server (in VS Code).\nFigure 1: Opening the web interface via Live Server.\n2. Upload an Image for Prediction On the web interface, click Choose File to select an image from your computer (dog or cat).\nThe image will appear in the preview box below.\nClick the Classify button to send the image to the system.\nFigure 2: Uploading an image for testing.\n3. Check the Prediction Result Once the API processes the image, the result will appear in the Prediction Result area.\nIf the system is connected correctly, you will see information such as:\nPredicted label (Cat or Dog) Figure 3: Displaying the prediction result.\n4. Check the Prediction History Scroll down to the Recent Prediction History section.\nThe list shows the most recent predictions stored in DynamoDB.\nFigure 4: Prediction history from DynamoDB.\n5. Debugging if You Encounter Errors If no result appears: Check the browser Console (F12 → Console tab) for API fetch errors. If a CORS error occurs: Make sure API Gateway → CORS is enabled for both OPTIONS and POST methods. If you get a permission error: Verify that the Lambda\u0026rsquo;s IAM Role has sagemaker:InvokeEndpoint and dynamodb:PutItem permissions. All done! Now you can test with different images and see the results in real time. Next, head over to the Clean up resources section to remove unused resources and avoid incurring charges.\n"
},
{
	"uri": "//localhost:1313/8-cleanup/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": " Goal: Delete all AWS resources created during the tutorial to avoid unnecessary charges.\n1. Delete Endpoint on SageMaker Delete Endpoint Open AWS Console → search for Amazon SageMaker.\nIn the left menu, choose Inference → Endpoints.\nImage 1: Go to Endpoint page.\nSelect your endpoint (e.g., dogcat-endpoint-xxxxxxxx) and click Delete.\nConfirm the deletion.\nImage 2: Delete Endpoint.\nDelete Endpoint Configurations In the left menu, choose Inference → Endpoints configurations.\nImage 3: Go to Endpoint Configurations page.\nSelect your endpoint configuration (e.g., dogcat-endpoint-xxxxxxxx) and click Delete.\nConfirm the deletion.\nImage 4: Delete Endpoint Configurations.\nDelete Model Still in SageMaker, choose Inference → Models.\nSelect the model, click Action → Delete.\nImage 4.1: Go to Model page.\nClick Delete to confirm.\nImage 4.2: Delete Model.\n2. Delete Lambda Functions Open AWS Console → search for Lambda.\nSelect the 2 functions you created, InvokeModelLambda and SaveHistoryLambda, then choose Action → Delete.\nImage 5: Go to Lambda page.\nType confirm in the input box, then click Delete.\nImage 6: Delete Lambda.\n3. Delete DynamoDB Table Go to DynamoDB service.\nIn the left menu, select Tables, tick the table you created PredictionHistory, and choose Delete.\nImage 7: Go to DynamoDB Tables page.\nType confirm and click Delete.\nImage 8: Delete PredictionHistory table.\n4. Delete API Gateway Go to API Gateway service, choose APIs in the left menu.\nSelect the API Gateway you created MLInferenceAPI and click Delete.\nImage 9: Go to API Gateway page.\nType confirm and click Delete.\nImage 10: Delete MLInferenceAPI.\n5. Delete IAM Roles (Optional but recommended) Go to IAM service, under Access Management, choose Roles.\nSearch and select IAM roles like InvokeModelLambda-role-xxx, SavePredictionHistory-role-xxx, AmazonSageMaker-ExecutionRole-xxx.\nImage 11: Go to IAM page.\nTip: Double-click Last activity to sort and find inactive roles quickly.\nType delete and click Delete.\nImage 12: Delete IAM Roles.\nNote: Make sure no other AWS services are still using these IAM roles.\n6. Delete S3 Bucket S3 Buckets are automatically created by SageMaker to store models.\nGo to S3, select the bucket to delete → Delete.\nImage 13: Go to S3 page.\nYou will see the warning This bucket is not empty. Click Empty bucket to remove all objects.\nImage 14: Empty bucket.\nThen type permanently delete and click Empty to completely delete the S3 bucket.\n✅ Done! All AWS resources have been removed, preventing any unwanted charges.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "🏁Workshop: Deploying a Real-Time Image Recognition Serverless Application with Lambda and SageMaker 🚀 Welcome to Workshop: Deploying a Real-Time Image Recognition Serverless Application with Lambda and SageMaker!. This is a 6-hour hands-on training program that helps you build a serverless web application for real-time image recognition using Amazon Web Services (AWS). By leveraging services such as S3, API Gateway, Lambda, DynamoDB, and SageMaker, you will learn how to deploy a complete system — from static front-end to backend — with automated backup and performance monitoring.\n🔰Introduction 🧠This workshop is designed to provide practical skills in serverless architecture and cloud computing for developers, IT students, and IT professionals. Through 8 practical sections, you will:\nBuild a basic web interface using HTML and CSS. Integrate a serverless backend with AWS Lambda, API Gateway, and DynamoDB. Upload a model to a SageMaker Endpoint. This workshop is suitable for educational institutions, training centers, and businesses looking to strengthen their cloud technology capabilities. Upon completion, you will have a real-world project to add to your portfolio and the skills to professionally deploy serverless applications.\nIntern Information 👨‍🎓 📛Full Nam: Nguyễn Trần Nhật Nam 🏫University: Trường Đại Học Công nghệ Thành phố Hồ Chí Minh (HUTECH) 🆔Student ID: 2180608712 📧Gmail: nhatnam.ngtr@gmail.com 💻GitHub: ngtrnhatnam 🧩Main Content 📦The workshop consists of 8 practical parts, from serverless introduction to deployment and resource cleanup:\n📚Part 📌Title 📝Description 1 📖Introduction Overview of serverless, benefits, and system architecture. 2 ⚙️Preparation Steps Set up AWS account, AWS CLI, and development environment. 3 🧠Quick Create SageMaker AI Create SageMaker and upload model to SageMaker Endpoint. 4 🎥Create DynamoDB Table Create DynamoDB to store prediction history. 5 🔗Lambda \u0026amp; API set up Create Lambda functions to handle logic and configure API Gateway integration. 6 🎨The Web Interface Design a simple interface with HTML and CSS. 7 🧪Check the Result Verify front-end, API, and backup functionality. 8 🧹Clean Up Resources Delete unused resources to avoid extra costs. 🛠️Tools Used::\n🖥️AWS Management Console, AWS CLI: Configure AWS services. 💻Visual Studio Code: Write Python, HTML/CSS/JS code. 🚀Setup \u0026amp; Run Instructions 🔽1. Open your terminal and run Open your terminal and run: git clone https://github.com/ngtrnhatnam/Serverless-ML-Inference-with-Lambda-and-SageMaker cd Serverless-ML-Inference-with-Lambda-and-SageMaker 🧰2. Cài Đặt Công Cụ AWS CLI: Install from https://aws.amazon.com/cli/. Python: Download from https://www.python.org/ to upload model. Visual Studio Code: Download from https://code.visualstudio.com/. 🧪3. Run \u0026amp; Test the Project Open main.html locally in your browser to check the static interface. Follow the workshop content for the full workflow. 🧱System Requirements ⚙️Requirement 💡Description 💻Operating System Windows, macOS, or Linux ☁️AWS Account AWS Free Tier account (recommended) 🔧Tools AWS CLI, Python (3.13+), Visual Studio Code 🌐Browser Chrome, Firefox, or Edge (JavaScript enabled) 📶Internet Stable connection to access AWS and GitHub 📚References 🔗The First Cloud Journey 🌟AWS Special Force Portal 🧠AWS Serverless Workshops 📖AWS Documentation 📬Contact For questions or support, feel free to reach out:\n📧Nguyễn Trần Nhật Nam: nhatnam.ngtr@gmail.com 🌟 Thank you for your interest in my workshop! Join in to master serverless technology and build modern applications with AWS! 🚀\n📄License This project is licensed under the terms of the MIT license.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]